"""
QA Utilities - Shared functions for chunking QA operations
Consolidates redundant functions from chunk_qc.py, merge_symlinks.py, and qa_app.py
"""

import json
import csv
import os
import glob
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path
from collections import Counter

from ..config import (
    SAMPLE_SIZE, CSV_EXPORT_LIMIT, METRICS_HISTORY_RETENTION,
    TIMESTAMP_FORMAT, FINAL_CHUNK_PATTERN
)
from ..schema import validate_chunk_schema, build_chunk_template

def load_chunks_streaming(path: str, batch_size: int = 1000) -> List[Dict[str, Any]]:
    """Load chunks from JSON file using streaming to handle large files."""
    import ijson
    
    chunks = []
    with open(path, 'rb') as f:
        parser = ijson.parse(f)
        current_chunk = {}
        in_chunk = False
        
        for prefix, event, value in parser:
            if prefix == 'item' and event == 'start_map':
                in_chunk = True
                current_chunk = {}
            elif prefix == 'item' and event == 'end_map':
                in_chunk = False
                chunks.append(current_chunk)
                current_chunk = {}
                
                # Yield batch if we've reached batch_size
                if len(chunks) >= batch_size:
                    yield chunks
                    chunks = []
            elif in_chunk and prefix.startswith('item.'):
                key = prefix.split('.', 1)[1]
                current_chunk[key] = value
        
        # Yield remaining chunks
        if chunks:
            yield chunks

def save_chunks_streaming(chunks: List[Dict[str, Any]], path: str, batch_size: int = 1000) -> None:
    """Save chunks to JSON file using streaming for memory efficiency."""
    import ijson
    
    with open(path, 'w') as f:
        f.write('[\n')
        for i, chunk in enumerate(chunks):
            if i > 0:
                f.write(',\n')
            json.dump(chunk, f, indent=2)
            
            # Flush periodically
            if i % batch_size == 0:
                f.flush()
        f.write('\n]')

def validate_chunk_structure(chunk: Dict[str, Any]) -> List[str]:
    """Validate individual chunk structure using schema."""
    return validate_chunk_schema(chunk)

def validate_chunks_batch(chunks: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Validate a batch of chunks and return validation results."""
    validation_result = {
        "total_chunks": len(chunks),
        "valid_chunks": 0,
        "invalid_chunks": 0,
        "errors": []
    }
    
    for i, chunk in enumerate(chunks):
        try:
            errors = validate_chunk_structure(chunk)
            if errors:
                validation_result["invalid_chunks"] += 1
                validation_result["errors"].append({
                    "chunk_index": i,
                    "chunk_id": chunk.get("chunk_id", f"unknown_{i}"),
                    "errors": errors
                })
            else:
                validation_result["valid_chunks"] += 1
        except Exception as e:
            validation_result["invalid_chunks"] += 1
            validation_result["errors"].append({
                "chunk_index": i,
                "chunk_id": chunk.get("chunk_id", f"unknown_{i}"),
                "errors": [f"Validation exception: {str(e)}"]
            })
    
    return validation_result

def load_chunks(path: str = None) -> List[Dict[str, Any]]:
    """Load chunks from JSON file with auto-detection of latest file."""
    if path is None:
        # Auto-detect latest final_chunks file
        chunk_files = glob.glob(f"data/chunks/final/{FINAL_CHUNK_PATTERN}")
        if not chunk_files:
            raise FileNotFoundError("No final chunks files found")
        
        # Sort by modification time and get the latest
        latest_file = max(chunk_files, key=os.path.getmtime)
        path = latest_file
        print(f"Auto-detected latest chunks file: {path}")
    
    try:
        with open(path, 'r') as f:
            chunks = json.load(f)
        
        # Validate chunks upon loading
        validation_result = validate_chunks_batch(chunks)
        if validation_result["invalid_chunks"] > 0:
            print(f"âš ï¸ Warning: {validation_result['invalid_chunks']} chunks failed validation")
            for error in validation_result["errors"][:5]:  # Show first 5 errors
                print(f"  - Chunk {error['chunk_id']}: {error['errors']}")
        
        print(f"Processed {len(chunks)} chunks...")
        return chunks
    except Exception as e:
        print(f"Error loading chunks from {path}: {e}")
        raise


def compute_metrics(chunks: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Compute comprehensive chunk metrics."""
    if not chunks:
        return {
            "run_time": datetime.now().isoformat(),
            "total_chunks": 0,
            "omit_flag_count": 0,
            "usable_chunks": 0,
            "quality_counts": {},
            "avg_chunk_length": 0,
            "fact_like_count": 0,
            "semantic_type_distribution": {},
            "retrieval_score_distribution": {}
        }
    
    # Basic metrics
    quality_counts = Counter([c.get("chunk_quality", "unknown") for c in chunks])
    omit_count = sum(1 for c in chunks if c.get("omit_flag", False))
    word_counts = [c.get("chunk_word_count", 0) for c in chunks if not c.get("omit_flag", False)]
    fact_like = sum(1 for c in chunks if c.get("is_fact_like"))
    
    # Semantic type distribution
    semantic_types = []
    for chunk in chunks:
        semantic_type = chunk.get("semantic_type", {})
        if isinstance(semantic_type, dict):
            primary = semantic_type.get("primary", "unknown")
        else:
            primary = semantic_type or "unknown"
        semantic_types.append(primary)
    
    semantic_distribution = Counter(semantic_types)
    
    # Retrieval score distribution
    retrieval_scores = [c.get("retrieval_score", 0) for c in chunks if not c.get("omit_flag", False)]
    score_ranges = {
        "0.0-0.2": sum(1 for s in retrieval_scores if 0 <= s < 0.2),
        "0.2-0.4": sum(1 for s in retrieval_scores if 0.2 <= s < 0.4),
        "0.4-0.6": sum(1 for s in retrieval_scores if 0.4 <= s < 0.6),
        "0.6-0.8": sum(1 for s in retrieval_scores if 0.6 <= s < 0.8),
        "0.8-1.0": sum(1 for s in retrieval_scores if 0.8 <= s <= 1.0)
    }
    
    return {
        "run_time": datetime.now().isoformat(),
        "total_chunks": len(chunks),
        "omit_flag_count": omit_count,
        "usable_chunks": len(chunks) - omit_count,
        "quality_counts": dict(quality_counts),
        "avg_chunk_length": round(sum(word_counts)/len(word_counts), 2) if word_counts else 0,
        "fact_like_count": fact_like,
        "semantic_type_distribution": dict(semantic_distribution),
        "retrieval_score_distribution": score_ranges
    }


def save_sample(chunks: List[Dict[str, Any]], sample_path: str, sample_size: int = 30) -> None:
    """Save a random sample of chunks."""
    if not chunks:
        print("âŒ No chunks to sample")
        return
    
    sample = random.sample(chunks, min(sample_size, len(chunks)))
    with open(sample_path, 'w', encoding='utf-8') as f:
        json.dump(sample, f, indent=2)
    print(f"ðŸ§ª Sample of {len(sample)} chunks saved to: {sample_path}")


def save_flagged_json(chunks: List[Dict[str, Any]], flagged_json_path: str) -> None:
    """Save flagged chunks to JSON."""
    flagged = [c for c in chunks if c.get("omit_flag")]
    with open(flagged_json_path, 'w', encoding='utf-8') as f:
        json.dump(flagged, f, indent=2)
    print(f"ðŸš« {len(flagged)} flagged chunks saved to: {flagged_json_path}")


def export_flagged_csv(chunks: List[Dict[str, Any]], csv_path: str, csv_export_limit: int = 50) -> None:
    """Export flagged chunks to CSV for human review."""
    flagged = [c for c in chunks if c.get("omit_flag")]
    if not flagged:
        print("âŒ No flagged chunks to export")
        return
    
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=["chunk_id", "chunk_word_count", "chunk_quality", "chunk_text"])
        writer.writeheader()
        for c in flagged[:csv_export_limit]:
            writer.writerow({
                "chunk_id": c["chunk_id"],
                "chunk_word_count": c.get("chunk_word_count", 0),
                "chunk_quality": c.get("chunk_quality", ""),
                "chunk_text": c.get("chunk_text", "")[:300].replace("\n", " ")
            })
    print(f"ðŸ“Š {len(flagged[:csv_export_limit])} flagged chunks exported to CSV: {csv_path}")


def save_metrics_json(metrics: Dict[str, Any], metrics_json_path: str, history_dir: str = None) -> None:
    """Save metrics to JSON with optional history."""
    with open(metrics_json_path, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2)
    print(f"ðŸ“Š Metrics saved to: {metrics_json_path}")
    
    # Save to history if directory provided
    if history_dir:
        os.makedirs(history_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        history_path = os.path.join(history_dir, f"chunk_metrics_{timestamp}.json")
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, indent=2)
        print(f"ðŸ“ˆ Metrics history saved to: {history_path}")


def save_summary_md(metrics: Dict[str, Any], summary_md_path: str) -> None:
    """Save metrics summary as markdown."""
    lines = [
        "# ðŸ“Š Chunking QA Summary",
        f"- Run time: `{metrics['run_time']}`",
        f"- Total chunks: **{metrics['total_chunks']}**",
        f"- Usable chunks: **{metrics['usable_chunks']}**",
        f"- Omitted chunks: **{metrics['omit_flag_count']}**",
        f"- Average word count: **{metrics['avg_chunk_length']}**",
        f"- Fact-like chunks: **{metrics['fact_like_count']}**",
        "",
        "### Quality Breakdown"
    ]
    
    for q, v in metrics["quality_counts"].items():
        lines.append(f"- `{q}`: {v}")
    
    if "semantic_type_distribution" in metrics:
        lines.extend([
            "",
            "### Semantic Type Distribution"
        ])
        # Convert dict to sorted list for display
        sorted_types = sorted(metrics["semantic_type_distribution"].items(), key=lambda x: x[1], reverse=True)
        for sem_type, count in sorted_types[:10]:
            lines.append(f"- `{sem_type}`: {count}")
    
    if "retrieval_score_distribution" in metrics:
        lines.extend([
            "",
            "### Retrieval Score Distribution"
        ])
        for score_range, count in metrics["retrieval_score_distribution"].items():
            lines.append(f"- `{score_range}`: {count}")
    
    with open(summary_md_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))
    print(f"ðŸ“ Summary saved to: {summary_md_path}")


def analyze_semantic_types_histogram(chunks: List[dict]) -> dict:
    """Analyze semantic type distribution."""
    semantic_types = []
    for chunk in chunks:
        semantic_type = chunk.get("semantic_type", {})
        if isinstance(semantic_type, dict):
            primary = semantic_type.get("primary", "unknown")
        else:
            primary = semantic_type or "unknown"
        semantic_types.append(primary)
    
    counter = Counter(semantic_types)
    return {
        "total_chunks": len(chunks),
        "semantic_type_counts": dict(counter),
        "most_common": counter.most_common(20)
    }


def print_semantic_summary(histogram_data: dict) -> None:
    """Print semantic type analysis summary."""
    print("\nðŸŽ¯ SEMANTIC TYPE ANALYSIS")
    print("=" * 50)
    print(f"Total chunks analyzed: {histogram_data['total_chunks']}")
    print(f"Unique semantic types: {len(histogram_data['semantic_type_counts'])}")
    print("\nTop 10 semantic types:")
    for i, (sem_type, count) in enumerate(histogram_data['most_common'][:10], 1):
        percentage = (count / histogram_data['total_chunks']) * 100
        print(f"{i:2d}. {sem_type:<25} {count:>5} ({percentage:>5.1f}%)")
    
    # Check for potential issues
    if histogram_data['total_chunks'] > 0:
        other_count = histogram_data['semantic_type_counts'].get('other', 0)
        other_percentage = (other_count / histogram_data['total_chunks']) * 100
        if other_percentage > 30:
            print(f"\nâš ï¸  WARNING: High 'other' percentage ({other_percentage:.1f}%) - semantic tagging may need improvement")
        else:
            print(f"\nâœ… Good semantic distribution - 'other' percentage: {other_percentage:.1f}%")
    else:
        print(f"\nâš ï¸  No chunks to analyze")


def save_semantic_analysis(histogram_data: dict, output_path: str) -> None:
    """Save semantic analysis to JSON."""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(histogram_data, f, indent=2)
    print(f"ðŸ“Š Semantic analysis saved to: {output_path}") 